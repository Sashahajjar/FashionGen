{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-Gen Multi-Modal Classification\n",
    "\n",
    "This notebook runs the Fashion-Gen project on Google Colab with GPU support.\n",
    "\n",
    "## Setup Instructions\n",
    "1. Upload this notebook to Google Colab\n",
    "2. Run all cells in order\n",
    "3. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install torch torchvision numpy matplotlib Pillow scikit-learn h5py -q\n",
    "\n",
    "# Verify GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Project from GitHub\n",
    "\n",
    "Clone the FashionGen repository from GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/Sashahajjar/FashionGen.git\n",
    "\n",
    "# Find the cloned project folder (handles different repo names)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# The repo will be cloned to /content/FashionGen\n",
    "# But let's make it flexible in case the folder name is different\n",
    "possible_paths = ['/content/FashionGen', '/content/fashiongen-project']\n",
    "project_path = None\n",
    "\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        project_path = path\n",
    "        break\n",
    "\n",
    "# If not found, search for it\n",
    "if project_path is None:\n",
    "    for item in os.listdir('/content'):\n",
    "        full_path = f'/content/{item}'\n",
    "        if os.path.isdir(full_path) and ('fashion' in item.lower() or 'FashionGen' in item):\n",
    "            project_path = full_path\n",
    "            break\n",
    "\n",
    "if project_path:\n",
    "    os.chdir(project_path)\n",
    "    sys.path.insert(0, project_path)\n",
    "    print(f\"‚úì Project found at: {project_path}\")\n",
    "    print(f\"‚úì Current directory: {os.getcwd()}\")\n",
    "    print(f\"‚úì Added to Python path\")\n",
    "else:\n",
    "    print(\"‚úó Project folder not found. Please check the clone was successful.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify project structure\n",
    "import os\n",
    "print(\"Project structure:\")\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    level = root.replace('.', '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:5]:  # Show first 5 files\n",
    "        print(f\"{subindent}{file}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"{subindent}... and {len(files) - 5} more files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Fashion-Gen Dataset from Kaggle\n",
    "\n",
    "The Fashion-Gen dataset is available on Kaggle: https://www.kaggle.com/datasets/bothin/fashiongen-validation/data\n",
    "\n",
    "**Steps to download:**\n",
    "1. Go to Kaggle.com and sign in\n",
    "2. Go to Account ‚Üí API ‚Üí Create New API Token\n",
    "3. Upload the `kaggle.json` file in the cell below\n",
    "4. The dataset will be automatically downloaded\n",
    "\n",
    "**Note:** If you skip this step, the project will use mock data for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Kaggle API\n",
    "%pip install kaggle -q\n",
    "\n",
    "# ============================================================\n",
    "# ‚ö†Ô∏è  YOU MUST ADD YOUR OWN CREDENTIALS HERE! ‚ö†Ô∏è\n",
    "# ============================================================\n",
    "# \n",
    "# Get your credentials from Kaggle:\n",
    "# 1. Go to https://www.kaggle.com ‚Üí Settings ‚Üí API\n",
    "# 2. Click \"Create New API Token\" (downloads kaggle.json)\n",
    "# 3. Open kaggle.json and copy your username and key\n",
    "# 4. Paste them below:\n",
    "#\n",
    "# ============================================================\n",
    "\n",
    "# üëá REPLACE THESE WITH YOUR ACTUAL CREDENTIALS üëá\n",
    "KAGGLE_USERNAME = \"\"  # ‚¨ÖÔ∏è PASTE YOUR KAGGLE USERNAME HERE\n",
    "KAGGLE_KEY = \"\"       # ‚¨ÖÔ∏è PASTE YOUR API TOKEN HERE (starts with KGAT_)\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DIRECT DOWNLOAD FROM KAGGLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if credentials were pasted\n",
    "if KAGGLE_USERNAME and KAGGLE_KEY:\n",
    "    # Use pasted credentials\n",
    "    kaggle_config = {\n",
    "        \"username\": KAGGLE_USERNAME.strip(),\n",
    "        \"key\": KAGGLE_KEY.strip()\n",
    "    }\n",
    "    print(\"‚úì Using pasted credentials\")\n",
    "else:\n",
    "    # Try uploading kaggle.json file instead\n",
    "    print(\"\\nüìÅ No credentials pasted. Upload kaggle.json file instead:\")\n",
    "    print(\"   (Or go back and paste your username and key above)\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    kaggle_config = None\n",
    "    if uploaded:\n",
    "        for filename in uploaded.keys():\n",
    "            if 'kaggle' in filename.lower() and filename.endswith('.json'):\n",
    "                with open(filename, 'r') as f:\n",
    "                    kaggle_config = json.load(f)\n",
    "                os.remove(filename)  # Remove for security\n",
    "                print(f\"‚úì Loaded credentials from {filename}\")\n",
    "                break\n",
    "\n",
    "# Set up Kaggle API if credentials provided\n",
    "if kaggle_config:\n",
    "    # Create .kaggle directory\n",
    "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "    \n",
    "    # Write kaggle.json\n",
    "    with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "        json.dump(kaggle_config, f)\n",
    "    \n",
    "    # Set proper permissions\n",
    "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úì Kaggle API credentials configured!\")\n",
    "    print(\"\\nüì• Downloading Fashion-Gen dataset from Kaggle...\")\n",
    "    print(\"   This may take a few minutes...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Download dataset with better error handling\n",
    "    print(\"\\nüì• Starting download...\")\n",
    "    import subprocess\n",
    "    result = subprocess.run(\n",
    "        ['kaggle', 'datasets', 'download', '-d', 'bothin/fashiongen-validation', '-p', 'data/'],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    # Print output\n",
    "    if result.stdout:\n",
    "        print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"Errors/Warnings:\", result.stderr)\n",
    "    \n",
    "    # Check if download was successful\n",
    "    import zipfile\n",
    "    zip_files = [f for f in os.listdir('data/') if f.endswith('.zip')]\n",
    "    \n",
    "    if zip_files:\n",
    "        print(f\"\\n‚úÖ Download successful! Found {len(zip_files)} zip file(s)\")\n",
    "        for zip_file in zip_files:\n",
    "            zip_path = f'data/{zip_file}'\n",
    "            size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "            print(f\"  - {zip_file} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            print(f\"\\nüì¶ Extracting {zip_file}...\")\n",
    "            try:\n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall('data/')\n",
    "                print(f\"‚úÖ Extracted {zip_file} successfully!\")\n",
    "                os.remove(zip_path)\n",
    "                print(f\"üóëÔ∏è Removed zip file\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error extracting {zip_file}: {e}\")\n",
    "        \n",
    "        # Verify .h5 files after extraction\n",
    "        h5_files = [f for f in os.listdir('data/') if f.endswith('.h5')]\n",
    "        if h5_files:\n",
    "            print(f\"\\n‚úÖ Found {len(h5_files)} .h5 file(s) after extraction:\")\n",
    "            for h5_file in h5_files:\n",
    "                size_mb = os.path.getsize(f'data/{h5_file}') / (1024 * 1024)\n",
    "                print(f\"  - {h5_file} ({size_mb:.1f} MB)\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è No .h5 files found after extraction. Checking zip contents...\")\n",
    "            # List contents of zip to see what's inside\n",
    "            for zip_file in zip_files:\n",
    "                zip_path = f'data/{zip_file}'\n",
    "                try:\n",
    "                    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                        print(f\"\\nContents of {zip_file}:\")\n",
    "                        for name in z.namelist()[:10]:  # Show first 10 files\n",
    "                            print(f\"  - {name}\")\n",
    "                        if len(z.namelist()) > 10:\n",
    "                            print(f\"  ... and {len(z.namelist()) - 10} more files\")\n",
    "                except:\n",
    "                    pass\n",
    "    else:\n",
    "        print(\"\\n‚ùå Download failed - no zip files found in data/\")\n",
    "        print(f\"Return code: {result.returncode}\")\n",
    "        if result.returncode != 0:\n",
    "            print(\"\\nüí° Possible issues:\")\n",
    "            print(\"  1. Dataset name might be incorrect\")\n",
    "            print(\"  2. You might need to accept dataset terms on Kaggle website\")\n",
    "            print(\"  3. Check if the dataset is public and accessible\")\n",
    "            print(\"\\nTry:\")\n",
    "            print(\"  - Visit: https://www.kaggle.com/datasets/bothin/fashiongen-validation/data\")\n",
    "            print(\"  - Click 'Download' button and accept terms\")\n",
    "            print(\"  - Then use Method B to upload the file manually\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    if zip_files or h5_files:\n",
    "        print(\"‚úÖ Dataset download process completed!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Dataset download did not complete successfully\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\\n‚ö† No credentials provided. Will use mock data for training.\")\n",
    "    print(\"\\nTo download the real dataset:\")\n",
    "    print(\"  1. Get your API token from Kaggle Settings ‚Üí API\")\n",
    "    print(\"  2. Paste your username and key in the variables above\")\n",
    "    print(\"  3. Run this cell again\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method B: Upload HDF5 File (If you already have it)\n",
    "\n",
    "**Only use this if you already downloaded the dataset:**\n",
    "- Upload the `.h5` file(s) directly below\n",
    "- Or upload a zip file and it will be extracted automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual upload of HDF5 files (No API token needed!)\n",
    "from google.colab import files\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"UPLOAD FASHION-GEN HDF5 FILES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìÅ Click 'Choose Files' below to upload your .h5 file(s)\")\n",
    "print(\"   (Downloaded from Kaggle dataset page)\")\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "\n",
    "# Create data directory\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Upload files\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "if uploaded:\n",
    "    # Move uploaded files to data directory\n",
    "    for filename in uploaded.keys():\n",
    "        # Check if it's a zip file\n",
    "        if filename.endswith('.zip'):\n",
    "            print(f\"üì¶ Extracting {filename}...\")\n",
    "            zip_path = f'/content/{filename}'\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall('data/')\n",
    "            os.remove(zip_path)\n",
    "            print(f\"‚úì Extracted {filename}\")\n",
    "        # Check if it's an HDF5 file\n",
    "        elif filename.endswith('.h5'):\n",
    "            import shutil\n",
    "            shutil.move(filename, f'data/{filename}')\n",
    "            print(f\"‚úì Moved {filename} to data/\")\n",
    "        else:\n",
    "            # Move other files to data directory\n",
    "            import shutil\n",
    "            shutil.move(filename, f'data/{filename}')\n",
    "            print(f\"‚úì Moved {filename} to data/\")\n",
    "    \n",
    "    print(\"\\n‚úì Files uploaded successfully!\")\n",
    "else:\n",
    "    print(\"‚ö† No files uploaded. Will use mock data for training.\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset files and search for .h5 files\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SEARCHING FOR DATASET FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Search in multiple locations\n",
    "search_paths = [\n",
    "    'data/',\n",
    "    '/content/data/',\n",
    "    '/content/',\n",
    "    '.',\n",
    "    'FashionGen/data/',\n",
    "    '/content/FashionGen/data/'\n",
    "]\n",
    "\n",
    "h5_files = []\n",
    "zip_files = []\n",
    "\n",
    "print(\"\\nüîç Searching for .h5 files...\")\n",
    "for path in search_paths:\n",
    "    if os.path.exists(path):\n",
    "        # Search for .h5 files\n",
    "        for h5_file in glob.glob(os.path.join(path, '**/*.h5'), recursive=True):\n",
    "            if h5_file not in h5_files:\n",
    "                h5_files.append(h5_file)\n",
    "        \n",
    "        # Search for .zip files (might not be extracted)\n",
    "        for zip_file in glob.glob(os.path.join(path, '**/*.zip'), recursive=True):\n",
    "            if 'fashiongen' in zip_file.lower() and zip_file not in zip_files:\n",
    "                zip_files.append(zip_file)\n",
    "\n",
    "# Check current directory structure\n",
    "print(\"\\nüìÅ Current directory:\", os.getcwd())\n",
    "print(\"\\nüìÇ Contents of data/ folder:\")\n",
    "if os.path.exists('data/'):\n",
    "    for item in os.listdir('data/'):\n",
    "        item_path = os.path.join('data', item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"  üìÅ {item}/\")\n",
    "        else:\n",
    "            size_mb = os.path.getsize(item_path) / (1024 * 1024)\n",
    "            print(f\"  üìÑ {item} ({size_mb:.2f} MB)\")\n",
    "\n",
    "# Report findings\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if h5_files:\n",
    "    print(f\"‚úÖ Found {len(h5_files)} HDF5 file(s):\")\n",
    "    for h5_file in h5_files:\n",
    "        size_mb = os.path.getsize(h5_file) / (1024 * 1024)\n",
    "        print(f\"  - {h5_file} ({size_mb:.1f} MB)\")\n",
    "    print(\"\\n‚úÖ Real dataset is ready for training!\")\n",
    "elif zip_files:\n",
    "    print(f\"‚ö†Ô∏è Found {len(zip_files)} zip file(s) that need extraction:\")\n",
    "    for zip_file in zip_files:\n",
    "        size_mb = os.path.getsize(zip_file) / (1024 * 1024)\n",
    "        print(f\"  - {zip_file} ({size_mb:.1f} MB)\")\n",
    "    print(\"\\nüí° The dataset might be in a zip file. Let's extract it...\")\n",
    "    import zipfile\n",
    "    for zip_file in zip_files:\n",
    "        print(f\"\\nüì¶ Extracting {zip_file}...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "                zip_ref.extractall('data/')\n",
    "            print(f\"‚úÖ Extracted {zip_file}\")\n",
    "            # Remove zip after extraction\n",
    "            os.remove(zip_file)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting {zip_file}: {e}\")\n",
    "    \n",
    "    # Search again after extraction\n",
    "    print(\"\\nüîç Searching again after extraction...\")\n",
    "    h5_files = []\n",
    "    for h5_file in glob.glob('data/**/*.h5', recursive=True):\n",
    "        h5_files.append(h5_file)\n",
    "    \n",
    "    if h5_files:\n",
    "        print(f\"‚úÖ Now found {len(h5_files)} HDF5 file(s)!\")\n",
    "        for h5_file in h5_files:\n",
    "            size_mb = os.path.getsize(h5_file) / (1024 * 1024)\n",
    "            print(f\"  - {h5_file} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"‚ùå No .h5 files or dataset zip files found!\")\n",
    "    print(\"\\nüí° The Kaggle download might have failed or files are in a different location.\")\n",
    "    print(\"\\nTry this:\")\n",
    "    print(\"  1. Check if the download completed successfully\")\n",
    "    print(\"  2. Re-run the Kaggle download cell\")\n",
    "    print(\"  3. Or manually upload the .h5 file using Method B\")\n",
    "\n",
    "# Create data directories if they don't exist\n",
    "os.makedirs('data/images', exist_ok=True)\n",
    "os.makedirs('data/captions', exist_ok=True)\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Download Files One at a Time (More Reliable)\n",
    "\n",
    "Download validation file first (smaller, faster), then training file separately.\n",
    "This is more reliable for large files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download validation file FIRST (1.8 GB - smaller, more reliable)\n",
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: DOWNLOAD VALIDATION FILE (1.8 GB)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüì• Downloading: fashiongen_256_256_validation.h5\")\n",
    "print(\"   Size: 1.8 GB\")\n",
    "print(\"   Estimated time: 5-10 minutes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "os.chdir('/content/FashionGen')\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Download validation file\n",
    "result = subprocess.run(\n",
    "    ['kaggle', 'datasets', 'download', 'bothin/fashiongen-validation', \n",
    "     '-f', 'fashiongen_256_256_validation.h5', '-p', 'data/'],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    timeout=900  # 15 minutes timeout\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n‚è±Ô∏è  Download took: {int(elapsed // 60)}m {int(elapsed % 60)}s\")\n",
    "print(f\"Return code: {result.returncode}\")\n",
    "\n",
    "if result.stdout:\n",
    "    print(\"\\nOutput:\", result.stdout[:300])\n",
    "if result.stderr and result.returncode != 0:\n",
    "    print(\"\\nErrors:\", result.stderr[:300])\n",
    "\n",
    "# Check and extract\n",
    "if os.path.exists('data/'):\n",
    "    files = os.listdir('data/')\n",
    "    zip_files = [f for f in files if f.endswith('.zip') and 'validation' in f.lower()]\n",
    "    h5_files = [f for f in files if f.endswith('.h5') and 'validation' in f.lower()]\n",
    "    \n",
    "    if zip_files:\n",
    "        print(f\"\\n‚úÖ Found zip: {zip_files[0]}\")\n",
    "        print(\"   Extracting...\")\n",
    "        try:\n",
    "            with zipfile.ZipFile(f'data/{zip_files[0]}', 'r') as z:\n",
    "                z.extractall('data/')\n",
    "            os.remove(f'data/{zip_files[0]}')\n",
    "            print(\"   ‚úÖ Extracted!\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {e}\")\n",
    "    \n",
    "    # Check final result\n",
    "    files = os.listdir('data/')\n",
    "    h5_files = [f for f in files if f.endswith('.h5') and 'validation' in f.lower()]\n",
    "    \n",
    "    if h5_files:\n",
    "        size_mb = os.path.getsize(f'data/{h5_files[0]}') / (1024 * 1024)\n",
    "        print(f\"\\n‚úÖ SUCCESS! Validation file ready: {h5_files[0]} ({size_mb:.1f} MB)\")\n",
    "        print(\"\\nüí° Now run the next cell to download the training file\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Validation file not found. Check errors above.\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training file SECOND (14.4 GB - large, may take 30+ minutes)\n",
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2: DOWNLOAD TRAINING FILE (14.4 GB)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚ö†Ô∏è  WARNING: This is a VERY LARGE file!\")\n",
    "print(\"   - Size: 14.4 GB\")\n",
    "print(\"   - Estimated time: 30-60 minutes\")\n",
    "print(\"   - Keep Colab open during download\")\n",
    "print(\"   - May timeout in free tier\")\n",
    "print(\"\\nüí° If this fails, consider using manual download from Kaggle website\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "os.chdir('/content/FashionGen')\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Download training file with longer timeout\n",
    "print(\"\\nüì• Starting download...\")\n",
    "print(\"   This will take a while - please be patient!\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['kaggle', 'datasets', 'download', 'bothin/fashiongen-validation', \n",
    "     '-f', 'fashiongen_256_256_train.h5', '-p', 'data/'],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    timeout=7200  # 2 hour timeout for very large files\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "elapsed_min = int(elapsed // 60)\n",
    "elapsed_sec = int(elapsed % 60)\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Download took: {elapsed_min}m {elapsed_sec}s\")\n",
    "print(f\"Return code: {result.returncode}\")\n",
    "\n",
    "if result.returncode == -9:\n",
    "    print(\"\\n‚ùå Process was killed (return code -9)\")\n",
    "    print(\"   This usually means:\")\n",
    "    print(\"   - Download timed out\")\n",
    "    print(\"   - Out of memory\")\n",
    "    print(\"   - Process killed by system\")\n",
    "    print(\"\\nüí° Solutions:\")\n",
    "    print(\"   1. Try manual download from Kaggle website\")\n",
    "    print(\"   2. Use Colab Pro for longer sessions\")\n",
    "    print(\"   3. Download in smaller chunks (if available)\")\n",
    "\n",
    "if result.stdout:\n",
    "    print(\"\\nOutput:\", result.stdout[:500])\n",
    "if result.stderr and result.returncode != 0:\n",
    "    print(\"\\nErrors:\", result.stderr[:500])\n",
    "\n",
    "# Check and extract\n",
    "if os.path.exists('data/'):\n",
    "    files = os.listdir('data/')\n",
    "    zip_files = [f for f in files if f.endswith('.zip') and 'train' in f.lower()]\n",
    "    h5_files = [f for f in files if f.endswith('.h5') and 'train' in f.lower()]\n",
    "    \n",
    "    if zip_files:\n",
    "        zip_path = f'data/{zip_files[0]}'\n",
    "        zip_size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "        print(f\"\\n‚úÖ Found zip: {zip_files[0]} ({zip_size_mb:.1f} MB)\")\n",
    "        print(\"   Extracting (this may take several minutes)...\")\n",
    "        try:\n",
    "            extract_start = time.time()\n",
    "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                z.extractall('data/')\n",
    "            extract_time = time.time() - extract_start\n",
    "            os.remove(zip_path)\n",
    "            print(f\"   ‚úÖ Extracted in {int(extract_time // 60)}m {int(extract_time % 60)}s!\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Extraction error: {e}\")\n",
    "    \n",
    "    # Check final result\n",
    "    files = os.listdir('data/')\n",
    "    h5_files = [f for f in files if f.endswith('.h5')]\n",
    "    \n",
    "    if h5_files:\n",
    "        print(f\"\\n‚úÖ SUCCESS! Found {len(h5_files)} .h5 file(s):\")\n",
    "        total_size = 0\n",
    "        for hf in h5_files:\n",
    "            size_mb = os.path.getsize(f'data/{hf}') / (1024 * 1024)\n",
    "            total_size += size_mb\n",
    "            print(f\"  - {hf} ({size_mb:.1f} MB)\")\n",
    "        print(f\"\\nüìä Total dataset size: {total_size:.1f} MB ({total_size/1024:.2f} GB)\")\n",
    "        print(\"\\nüéâ Complete dataset ready for training!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Training file not found. Download may have failed.\")\n",
    "        print(\"   Check errors above or try manual download.\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "\n",
    "Train the model with your data (or mock data for testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training script\n",
    "from training.train import train\n",
    "\n",
    "# Run training\n",
    "# This will use mock data if no real data is available\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Evaluate the trained model on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import evaluation script\n",
    "from training.evaluate import main as evaluate\n",
    "\n",
    "# Run evaluation\n",
    "evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inference Demo\n",
    "\n",
    "Run inference on sample images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import inference script\n",
    "from inference.demo import demo\n",
    "\n",
    "# Run inference demo\n",
    "demo()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
